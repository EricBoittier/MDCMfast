Assuming unrestricted shared filesystem usage.
None
host: pc-mm025
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 10
Rules claiming more threads will be scaled down.
Job stats:
job                      count
---------------------  -------
all                          1
fit_atomic_mdcm              3
fit_molecular_mdcm           7
fit_multipoles               1
generate_charmm_files        7
total                       19

Select jobs to execute...
Execute 1 jobs...
[Mon May 19 12:24:26 2025]
localrule fit_multipoles:
    input: /home/boittier/Documents/github/MDCMfast/examples/ref/h2o-pot.cube, /home/boittier/Documents/github/MDCMfast/examples/ref/h2o-dens.cube
    output: /home/boittier/Documents/github/MDCMfast/results/h2o/1-mtp-fit/fitted-mtpl.dat
    jobid: 3
    reason: Missing output files: /home/boittier/Documents/github/MDCMfast/results/h2o/1-mtp-fit/fitted-mtpl.dat
    resources: tmpdir=/tmp

Waiting at most 600 seconds for missing files:
/home/boittier/Documents/github/MDCMfast/results/h2o/1-mtp-fit/fitted-mtpl.dat (missing locally)
Terminating processes on user request, this might take some time.
Complete log(s): /home/boittier/Documents/github/MDCMfast/examples/workflows/basic-fit/.snakemake/log/2025-05-19T122426.580237.snakemake.log
WorkflowError:
At least one job did not complete successfully.
